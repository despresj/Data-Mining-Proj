{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0545e4f",
   "metadata": {},
   "source": [
    "# Modeling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad45d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "testing_models = True\n",
    "\n",
    "forecast_horizon = 547\n",
    "\n",
    "from beepy import beep\n",
    "# TODO:\n",
    "# Add forecasting models that work\n",
    "# Determine when a forecasting model works given a time series features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9618e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7eda",
   "metadata": {},
   "source": [
    "# tune models on a subset of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset for testing\n",
    "\n",
    "if testing_models:\n",
    "    train = train[train.store_item.isin(['1-1', '1-2', '1-3'])]\n",
    "    test = test[test.store_item.isin(['1-1', '1-2', '1-3'])]\n",
    "else: \n",
    "    from warnings import filterwarnings\n",
    "    filterwarnings('ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28477e31",
   "metadata": {},
   "source": [
    "# Create df to populate with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb57803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "date_list = [train.index[-1] + timedelta(days=x+1) for x in range(forecast_horizon)]\n",
    "horizon_end_date = date_list[-1]\n",
    "fcast_begin = date_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96c1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_item, dates = [], []\n",
    "for series in train.store_item.unique():\n",
    "    store_item.append(np.repeat(series, len(date_list)))\n",
    "    dates.append(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(\n",
    "    {\n",
    "        'store_item': [x for sub in store_item for x in sub],\n",
    "        'sales': test.sales\n",
    "    }, index=[x for sub in dates for x in sub]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08743ab3",
   "metadata": {},
   "source": [
    "# vector autoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9a52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737bf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autoreg(df, fcast, horizion_end):\n",
    "    preds_autoreg, trouble_series = [], []\n",
    "    for series in df.store_item.unique(): \n",
    "\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        try:\n",
    "            yhat = AutoReg(temp.sales, lags=5, old_names=False, seasonal=True, period=365)\\\n",
    "                .fit()\\\n",
    "                .predict(start = fcast, end = horizion_end)\n",
    "            preds_autoreg.append(yhat)\n",
    "        except np.linalg.LinAlgError:\n",
    "            trouble_series.append(series)\n",
    "            print(f'series {series} error')\n",
    "            \n",
    "    return [x for sub in preds_autoreg for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744e9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"autoreg\"] = fit_autoreg(df=train,fcast=fcast_begin, horizion_end=horizon_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122f5c5",
   "metadata": {},
   "source": [
    "# exp smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cbb84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from tqdm import tqdm # progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2289c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smooth_predictor(df, seas, fcast=fcast_begin, horizion_end=horizon_end_date, progress_bar=False):\n",
    "    exp_smooth_preds = []\n",
    "    trouble_series = []\n",
    "    for series in tqdm(df.store_item.unique(), disable= not progress_bar):\n",
    "        temp = train[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        try:\n",
    "            preds = ExponentialSmoothing(temp.sales,     \n",
    "                seasonal_periods=365,\n",
    "                trend=\"add\",\n",
    "                seasonal=seas,\n",
    "                use_boxcox=True,\n",
    "                initialization_method=\"estimated\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "            exp_smooth_preds.append(preds)\n",
    "        except ValueError:\n",
    "            trouble_series.append(series)\n",
    "            print(series)\n",
    "\n",
    "    return [x for sub in exp_smooth_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1359145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:915: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:915: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/statsmodels/tsa/holtwinters/model.py:915: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions[\"exp_smooth\"] = exp_smooth_predictor(df=train, seas=\"add\")\n",
    "predictions[\"exp_smooth_multi\"] = exp_smooth_predictor(df=train, seas=\"multiplicative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d328a",
   "metadata": {},
   "source": [
    "# ardl autoregressive distributed lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11944e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13255233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ardl_predictor(df, fcast=fcast_begin, horizion_end=horizon_end_date):\n",
    "    ardl_preds = []\n",
    "    for series in df.store_item.unique():\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        ardl_pred = ARDL(temp.sales, 365, period=365, trend=\"t\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "        ardl_preds.append(ardl_pred)\n",
    "    return [x for sub in ardl_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60d1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"ardl\"] = ardl_predictor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710826e4",
   "metadata": {},
   "source": [
    "# prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aca792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "# https://www.youtube.com/watch?v=pOYAXv15r3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b3d474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_inputs(df):\n",
    "    df = df.drop(\"store_item\", axis=1)\\\n",
    "        .reset_index()\n",
    "    df[\"unique_id\"] = series\n",
    "    df = df.rename(columns={\"sales\":\"y\", \"date\":\"ds\"})\n",
    "    return df[[\"ds\", \"y\", \"unique_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7c8c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_predictor(df, date_list=date_list):\n",
    "    prophet_preds = []\n",
    "    for series in df.store_item.unique():  \n",
    "        temp = df[df.store_item == series]\n",
    "        temp = strict_inputs(temp)\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(temp)\n",
    "        pred_frame = model.make_future_dataframe(periods=len(date_list), include_history=False)\n",
    "        preds = model.predict(pred_frame)\n",
    "        prophet_preds.append(preds.yhat)\n",
    "    return [x for sub in prophet_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d475290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -23.8441\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      94       2304.99    0.00059656       212.127    4.31e-06       0.001      145  LS failed, Hessian reset \n",
      "      99       2305.17   0.000825136       89.4793      0.9746      0.9746      150   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     193        2305.9    0.00037808       161.031   2.206e-06       0.001      316  LS failed, Hessian reset \n",
      "     199       2306.19    0.00069264       73.7016      0.3052           1      323   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     243       2306.29   4.25779e-05       86.2633   5.088e-07       0.001      415  LS failed, Hessian reset \n",
      "     271       2306.29   1.51602e-07       79.5501           1           1      452   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -34.5062\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       2717.63   0.000201329       78.4211      0.7713      0.7713      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       2721.23   0.000657679       64.9873      0.4638           1      262   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     266       2721.27   2.03817e-05       61.8377   4.043e-07       0.001      393  LS failed, Hessian reset \n",
      "     299       2721.27   6.35448e-06       61.8897       1.593      0.4364      432   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     365       2721.28   1.48875e-07       76.8861      0.3067           1      514   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -20.7053\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      98       2482.26   0.000209279       112.769   1.462e-06       0.001      192  LS failed, Hessian reset \n",
      "      99       2482.31    0.00124962       83.2433          10           1      194   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     114        2482.4   9.02554e-05       51.7204   1.639e-06       0.001      247  LS failed, Hessian reset \n",
      "     136       2482.41   2.62744e-05        85.761   3.638e-07       0.001      312  LS failed, Hessian reset \n",
      "     159       2482.41   1.24874e-07       61.4959      0.8433      0.8433      349   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "predictions[\"prophet\"] = prophet_predictor(df=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fdf7c6",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc6afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# pip install xgboost==0.80\n",
    "# the latest version kept crashing on me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7750819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import create_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "738c6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_predictor(df):\n",
    "    X_pred = create_features(pd.DataFrame(date_list, columns=[\"date\"]))\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    xgb_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        \n",
    "        X = create_features(pd.DataFrame(temp.index, columns=[\"date\"]))\n",
    "        \n",
    "        preds = reg.fit(X, temp.sales)\\\n",
    "            .predict(X_pred)\n",
    "        xgb_preds.append(preds)\n",
    "    return [x for sub in xgb_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5809476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"xgb_preds\"] = xgb_predictor(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ceacc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377a04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749afb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales = pd.concat([train, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ac763",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(f\"../data/predictions/predictions-{today.month}-{today.day}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134cc99",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d52c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557322dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fcastplotter(x):\n",
    "        \n",
    "    for store in store_sales.store_item.unique():\n",
    "        temp = store_sales[store_sales.store_item == store]\n",
    "        plt.figure()\n",
    "        plt.plot(temp.sales, \"-b\", label = \"sales\")\n",
    "        plt.plot(temp[x],  \"-r\", label = f\"Forecast {x} \")\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.ylim([0, None])\n",
    "        plt.title(f\"store {store}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n",
    "\n",
    "# for forecast in store_sales.columns[2:]:\n",
    "#     fcastplotter(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a240e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep\n",
    "beep()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
