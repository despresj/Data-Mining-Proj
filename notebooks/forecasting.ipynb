{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0545e4f",
   "metadata": {},
   "source": [
    "# Modeling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad45d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "testing_models = True\n",
    "\n",
    "forecast_horizon = 547\n",
    "\n",
    "from beepy import beep\n",
    "\n",
    "# set benchmark with fourier series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9618e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7eda",
   "metadata": {},
   "source": [
    "# tune models on a subset of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset for testing\n",
    "\n",
    "if testing_models:\n",
    "    train = train[train.store_item.isin(['1-1', '1-2', '1-3', '3-5', '6-4'])]\n",
    "    test = test[test.store_item.isin(['1-1', '1-2', '1-3', '3-5', '6-4'])]\n",
    "else: \n",
    "    from warnings import filterwarnings\n",
    "    filterwarnings('ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28477e31",
   "metadata": {},
   "source": [
    "# Create df to populate with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb57803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "date_list = [train.index[-1] + timedelta(days=x+1) for x in range(forecast_horizon)]\n",
    "horizon_end_date = date_list[-1]\n",
    "fcast_begin = date_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96c1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_item, dates = [], []\n",
    "for series in train.store_item.unique():\n",
    "    store_item.append(np.repeat(series, len(date_list)))\n",
    "    dates.append(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d1a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(\n",
    "    {\n",
    "        'store_item': [x for sub in store_item for x in sub],\n",
    "        'sales': test.sales\n",
    "    }, index=[x for sub in dates for x in sub]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495361f",
   "metadata": {},
   "source": [
    "# Fourier series (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5d8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://notebook.community/statsmodels/statsmodels.github.io/devel/examples/notebooks/generated/deterministics\n",
    "# from statsmodels.tsa.deterministic import Fourier, Seasonality, TimeTrend\n",
    "# from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "\n",
    "# index = temp.index\n",
    "# tt = TimeTrend(constant=True)\n",
    "# four = Fourier(period=365.25, order=2)\n",
    "# seas = Seasonality(period=7)\n",
    "# det_proc = DeterministicProcess(index, additional_terms=[tt, seas, four])\n",
    "# det_proc.in_sample().head(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29032365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2016-07-03    2.000000\n",
       "2016-07-04    2.706941\n",
       "2016-07-05    1.425936\n",
       "2016-07-06   -0.393719\n",
       "2016-07-07   -1.031247\n",
       "                ...   \n",
       "2017-12-27   -0.393719\n",
       "2017-12-28   -1.031247\n",
       "2017-12-29   -0.377148\n",
       "2017-12-30    0.140669\n",
       "2017-12-31   -0.563104\n",
       "Length: 547, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "\n",
    "fourier_gen = Fourier(11, order=2)\n",
    "\n",
    "temp = test[test.store_item == \"1-1\"]\n",
    "fourier_gen.in_sample(temp.index).sum(axis=1)\n",
    "# fourier_gen.out_of_sample(365, index=temp.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08743ab3",
   "metadata": {},
   "source": [
    "# vector autoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9a52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from tqdm import tqdm # progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "737bf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autoreg(df, fcast, horizion_end):\n",
    "    preds_autoreg, trouble_series = [], []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        try:\n",
    "            yhat = AutoReg(temp.sales, lags=5, old_names=False, seasonal=True, period=365)\\\n",
    "                .fit()\\\n",
    "                .predict(start = fcast, end = horizion_end)\n",
    "            preds_autoreg.append(yhat)\n",
    "        except np.linalg.LinAlgError:\n",
    "            trouble_series.append(series)\n",
    "            print(f'series {series} error')\n",
    "            \n",
    "    return [x for sub in preds_autoreg for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744e9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"autoreg\"] = fit_autoreg(df=train, fcast=fcast_begin, horizion_end=horizon_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122f5c5",
   "metadata": {},
   "source": [
    "# exp smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cbb84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2289c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smooth_predictor(df, seas, fcast=fcast_begin, horizion_end=horizon_end_date):\n",
    "    exp_smooth_preds = []\n",
    "    trouble_series = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        try:\n",
    "            preds = ExponentialSmoothing(temp.sales,     \n",
    "                seasonal_periods=365,\n",
    "                trend=\"add\",\n",
    "                seasonal=seas,\n",
    "                use_boxcox=True,\n",
    "                initialization_method=\"estimated\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "            exp_smooth_preds.append(preds)\n",
    "        except ValueError:\n",
    "            trouble_series.append(series)\n",
    "            print(series)\n",
    "\n",
    "    return [x for sub in exp_smooth_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"exp_smooth\"] = exp_smooth_predictor(df=train, seas=\"add\")\n",
    "# predictions[\"exp_smooth_multi\"] = exp_smooth_predictor(df=train, seas=\"multiplicative\") \n",
    "# multiplicative is slow and inaccurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d328a",
   "metadata": {},
   "source": [
    "# autoregressive distributed lag ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11944e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13255233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ardl_predictor(df, fcast=fcast_begin, horizion_end=horizon_end_date):\n",
    "    ardl_preds = []\n",
    "    for series in df.store_item.unique():\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        ardl_pred = ARDL(temp.sales, 365, period=365, trend=\"t\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "        ardl_preds.append(ardl_pred)\n",
    "    return [x for sub in ardl_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"ardl\"] = ardl_predictor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267edc47",
   "metadata": {},
   "source": [
    "# xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ddc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# pip install xgboost==0.80\n",
    "# the latest version kept crashing on me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65261423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import create_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e810b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_predictor(df, date_list=date_list):\n",
    "    X_pred = create_features(pd.DataFrame(date_list, columns=[\"date\"]))\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    xgb_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        X = create_features(pd.DataFrame(temp.index, columns=[\"date\"]))\n",
    "        preds = reg.fit(X, temp.sales)\\\n",
    "            .predict(X_pred)\n",
    "        xgb_preds.append(preds)\n",
    "    return [x for sub in xgb_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f96afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"xgb_preds\"] = xgb_predictor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710826e4",
   "metadata": {},
   "source": [
    "# prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "# https://www.youtube.com/watch?v=pOYAXv15r3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_inputs(df):\n",
    "    df = df.drop(\"store_item\", axis=1)\\\n",
    "        .reset_index()\n",
    "    df[\"unique_id\"] = series\n",
    "    df = df.rename(columns={\"sales\":\"y\", \"date\":\"ds\"})\n",
    "    return df[[\"ds\", \"y\", \"unique_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_predictor(df, date_list=date_list):\n",
    "    prophet_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):  \n",
    "        temp = df[df.store_item == series]\n",
    "        temp = strict_inputs(temp)\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(temp)\n",
    "        pred_frame = model.make_future_dataframe(periods=len(date_list), include_history=False)\n",
    "        preds = model.predict(pred_frame)\n",
    "        prophet_preds.append(preds.yhat)\n",
    "    return [x for sub in prophet_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -23.8441\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      94       2304.99    0.00059656       212.127    4.31e-06       0.001      145  LS failed, Hessian reset \n",
      "      99       2305.17   0.000825136       89.4793      0.9746      0.9746      150   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     193        2305.9    0.00037808       161.031   2.206e-06       0.001      316  LS failed, Hessian reset \n",
      "     199       2306.19    0.00069264       73.7016      0.3052           1      323   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     243       2306.29   4.25779e-05       86.2633   5.088e-07       0.001      415  LS failed, Hessian reset \n",
      "     271       2306.29   1.51602e-07       79.5501           1           1      452   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:02<00:05,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -34.5062\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       2717.63   0.000201329       78.4211      0.7713      0.7713      130   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       2721.23   0.000657679       64.9873      0.4638           1      262   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     266       2721.27   2.03817e-05       61.8377   4.043e-07       0.001      393  LS failed, Hessian reset \n",
      "     299       2721.27   6.35448e-06       61.8897       1.593      0.4364      432   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     365       2721.28   1.48875e-07       76.8861      0.3067           1      514   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -20.7053\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      98       2482.26   0.000209279       112.769   1.462e-06       0.001      192  LS failed, Hessian reset \n",
      "      99       2482.31    0.00124962       83.2433          10           1      194   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     114        2482.4   9.02554e-05       51.7204   1.639e-06       0.001      247  LS failed, Hessian reset \n",
      "     136       2482.41   2.62744e-05        85.761   3.638e-07       0.001      312  LS failed, Hessian reset \n",
      "     159       2482.41   1.24874e-07       61.4959      0.8433      0.8433      349   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"prophet\"] = prophet_predictor(df=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e73ca",
   "metadata": {},
   "source": [
    "# Neural prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceacc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "# https://neuralprophet.com/html/model/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(n_forecasts=1)\n",
    "def neural_prophet(df, date_list=date_list):\n",
    "    m_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        temp = strict_inputs(temp)\n",
    "        temp = temp[[\"y\", \"ds\"]]\n",
    "        temp.index.freq = \"d\"\n",
    "        m.fit(temp, freq=\"D\")\n",
    "        future = m.make_future_dataframe(temp, periods=len(date_list))\n",
    "        forecast = m.predict(future)\n",
    "        m_preds.append(forecast.yhat1)\n",
    "    return [x for sub in m_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88859427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import set_random_seed \n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc86597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO:NP.utils:Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "INFO:NP.config:Auto-set batch_size to 32\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 170\n",
      "INFO:NP.config:Auto-set epochs to 170\n",
      " 94%|█████████▎| 239/255 [00:01<00:00, 143.55it/s]\n",
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 3.11E-02, min: 1.13E+00\n",
      "INFO:NP.utils_torch:lr-range-test results: steep: 3.11E-02, min: 1.13E+00\n",
      "INFO - (NP.utils_torch.lr_range_test) - learning rate range test selected lr: 3.40E-01\n",
      "INFO:NP.utils_torch:learning rate range test selected lr: 3.40E-01\n",
      "Epoch[170/170]: 100%|██████████| 170/170 [00:11<00:00, 15.33it/s, SmoothL1Loss=0.0136, MAE=3.35, MSE=18.4, RegLoss=0]\n",
      " 33%|███▎      | 1/3 [00:12<00:25, 12.81s/it]WARNING - (NP.forecaster.fit) - Model has already been fitted. Re-fitting will produce different results.\n",
      "WARNING:NP.forecaster:Model has already been fitted. Re-fitting will produce different results.\n",
      "Epoch[170/170]: 100%|██████████| 170/170 [00:10<00:00, 15.46it/s, SmoothL1Loss=0.0409, MAE=5.9, MSE=55.4, RegLoss=0]\n",
      " 67%|██████▋   | 2/3 [00:23<00:11, 11.77s/it]WARNING - (NP.forecaster.fit) - Model has already been fitted. Re-fitting will produce different results.\n",
      "WARNING:NP.forecaster:Model has already been fitted. Re-fitting will produce different results.\n",
      "Epoch[170/170]: 100%|██████████| 170/170 [00:10<00:00, 15.60it/s, SmoothL1Loss=0.0252, MAE=4.6, MSE=34, RegLoss=0]\n",
      "100%|██████████| 3/3 [00:34<00:00, 11.60s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"neural_prophet\"] = neural_prophet(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749afb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales = pd.concat([train, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ac763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing_models:\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "    predictions.to_csv(f\"../data/predictions/predictions-{today.month}-{today.day}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134cc99",
   "metadata": {},
   "source": [
    "# plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a240e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep\n",
    "beep()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
