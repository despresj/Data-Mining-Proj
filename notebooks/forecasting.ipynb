{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0545e4f",
   "metadata": {},
   "source": [
    "# Modeling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad45d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "testing_models = False\n",
    "\n",
    "forecast_horizon = 547\n",
    "\n",
    "from beepy import beep\n",
    "\n",
    "# set benchmark with fourier series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9618e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e7eda",
   "metadata": {},
   "source": [
    "# tune models on a subset of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset for testing\n",
    "\n",
    "if testing_models:\n",
    "    train = train[train.store_item.isin(['1-1', '1-2', '1-3', '3-5', '6-4'])]\n",
    "    test = test[test.store_item.isin(['1-1', '1-2', '1-3', '3-5', '6-4'])]\n",
    "else: \n",
    "    from warnings import filterwarnings\n",
    "    filterwarnings('ignore')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28477e31",
   "metadata": {},
   "source": [
    "# Create df to populate with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb57803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "date_list = [train.index[-1] + timedelta(days=x+1) for x in range(forecast_horizon)]\n",
    "horizon_end_date = date_list[-1]\n",
    "fcast_begin = date_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96c1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_item, dates = [], []\n",
    "for series in train.store_item.unique():\n",
    "    store_item.append(np.repeat(series, len(date_list)))\n",
    "    dates.append(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1a615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(\n",
    "    {\n",
    "        'store_item': [x for sub in store_item for x in sub],\n",
    "        'sales': test.sales\n",
    "    }, index=[x for sub in dates for x in sub]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495361f",
   "metadata": {},
   "source": [
    "# Fourier series (benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5d8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://notebook.community/statsmodels/statsmodels.github.io/devel/examples/notebooks/generated/deterministics\n",
    "# from statsmodels.tsa.deterministic import Fourier, Seasonality, TimeTrend\n",
    "# from statsmodels.tsa.deterministic import DeterministicProcess\n",
    "\n",
    "# index = temp.index\n",
    "# tt = TimeTrend(constant=True)\n",
    "# four = Fourier(period=365.25, order=2)\n",
    "# seas = Seasonality(period=7)\n",
    "# det_proc = DeterministicProcess(index, additional_terms=[tt, seas, four])\n",
    "# det_proc.in_sample().head(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29032365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2016-07-03    2.000000\n",
       "2016-07-04    2.706941\n",
       "2016-07-05    1.425936\n",
       "2016-07-06   -0.393719\n",
       "2016-07-07   -1.031247\n",
       "                ...   \n",
       "2017-12-27   -0.393719\n",
       "2017-12-28   -1.031247\n",
       "2017-12-29   -0.377148\n",
       "2017-12-30    0.140669\n",
       "2017-12-31   -0.563104\n",
       "Length: 547, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from statsmodels.tsa.deterministic import Fourier\n",
    "\n",
    "fourier_gen = Fourier(11, order=2)\n",
    "\n",
    "temp = test[test.store_item == \"1-1\"]\n",
    "fourier_gen.in_sample(temp.index).sum(axis=1)\n",
    "# fourier_gen.out_of_sample(365, index=temp.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08743ab3",
   "metadata": {},
   "source": [
    "# vector autoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9a52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from tqdm import tqdm # progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737bf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_autoreg(df, fcast, horizion_end):\n",
    "    preds_autoreg, trouble_series = [], []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        try:\n",
    "            yhat = AutoReg(temp.sales, lags=5, old_names=False, seasonal=True, period=365)\\\n",
    "                .fit()\\\n",
    "                .predict(start = fcast, end = horizion_end)\n",
    "            preds_autoreg.append(yhat)\n",
    "        except np.linalg.LinAlgError:\n",
    "            trouble_series.append(series)\n",
    "            print(f'series {series} error')\n",
    "            \n",
    "    return [x for sub in preds_autoreg for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744e9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:24<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"autoreg\"] = fit_autoreg(df=train, fcast=fcast_begin, horizion_end=horizon_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122f5c5",
   "metadata": {},
   "source": [
    "# exp smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cbb84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2289c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_smooth_predictor(df, seas, fcast=fcast_begin, horizion_end=horizon_end_date):\n",
    "    exp_smooth_preds = []\n",
    "    trouble_series = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        try:\n",
    "            preds = ExponentialSmoothing(temp.sales,     \n",
    "                seasonal_periods=365,\n",
    "                trend=\"add\",\n",
    "                seasonal=seas,\n",
    "                use_boxcox=True,\n",
    "                initialization_method=\"estimated\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "            exp_smooth_preds.append(preds)\n",
    "        except ValueError:\n",
    "            trouble_series.append(series)\n",
    "            print(series)\n",
    "\n",
    "    return [x for sub in exp_smooth_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1359145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [15:07<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"exp_smooth\"] = exp_smooth_predictor(df=train, seas=\"add\")\n",
    "# predictions[\"exp_smooth_multi\"] = exp_smooth_predictor(df=train, seas=\"multiplicative\") \n",
    "# multiplicative is slow and inaccurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d328a",
   "metadata": {},
   "source": [
    "# autoregressive distributed lag ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11944e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13255233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ardl_predictor(df, fcast=fcast_begin, horizion_end=horizon_end_date):\n",
    "    ardl_preds = []\n",
    "    for series in df.store_item.unique():\n",
    "        temp = df[df.store_item == series]\n",
    "        temp.index.freq = \"d\"\n",
    "        \n",
    "        ardl_pred = ARDL(temp.sales, 365, period=365, trend=\"t\")\\\n",
    "            .fit()\\\n",
    "            .predict(start = fcast, end = horizion_end)\n",
    "        ardl_preds.append(ardl_pred)\n",
    "    return [x for sub in ardl_preds for x in sub]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b60d1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"ardl\"] = ardl_predictor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267edc47",
   "metadata": {},
   "source": [
    "# xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b17ddc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# pip install xgboost==0.80\n",
    "# the latest version kept crashing on me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65261423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import create_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e810b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_predictor(df, date_list=date_list):\n",
    "    X_pred = create_features(pd.DataFrame(date_list, columns=[\"date\"]))\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    xgb_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        X = create_features(pd.DataFrame(temp.index, columns=[\"date\"]))\n",
    "        preds = reg.fit(X, temp.sales)\\\n",
    "            .predict(X_pred)\n",
    "        xgb_preds.append(preds)\n",
    "    return [x for sub in xgb_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f96afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:16<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions[\"xgb_preds\"] = xgb_predictor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710826e4",
   "metadata": {},
   "source": [
    "# prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aca792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "# https://www.youtube.com/watch?v=pOYAXv15r3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b3d474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_inputs(df):\n",
    "    df = df.drop(\"store_item\", axis=1)\\\n",
    "        .reset_index()\n",
    "    df[\"unique_id\"] = series\n",
    "    df = df.rename(columns={\"sales\":\"y\", \"date\":\"ds\"})\n",
    "    return df[[\"ds\", \"y\", \"unique_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c8c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_predictor(df, date_list=date_list):\n",
    "    prophet_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):  \n",
    "        temp = df[df.store_item == series]\n",
    "        temp = strict_inputs(temp)\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(temp)\n",
    "        pred_frame = model.make_future_dataframe(periods=len(date_list), include_history=False)\n",
    "        preds = model.predict(pred_frame)\n",
    "        prophet_preds.append(preds.yhat)\n",
    "    return [x for sub in prophet_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"prophet\"] = prophet_predictor(df=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e73ca",
   "metadata": {},
   "source": [
    "# Neural prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ceacc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "# https://neuralprophet.com/html/model/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1377a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NeuralProphet(n_forecasts=1)\n",
    "def neural_prophet(df, date_list=date_list):\n",
    "    m_preds = []\n",
    "    for series in tqdm(df.store_item.unique()):\n",
    "        temp = df[df.store_item == series]\n",
    "        temp = strict_inputs(temp)\n",
    "        temp = temp[[\"y\", \"ds\"]]\n",
    "        temp.index.freq = \"d\"\n",
    "        m.fit(temp, freq=\"D\")\n",
    "        future = m.make_future_dataframe(temp, periods=len(date_list))\n",
    "        forecast = m.predict(future)\n",
    "        m_preds.append(forecast.yhat1)\n",
    "    return [x for sub in m_preds for x in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88859427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import set_random_seed \n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc86597",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"neural_prophet\"] = neural_prophet(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "749afb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales = pd.concat([train, predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e44ac763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not testing_models:\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "    predictions.to_csv(f\"../data/predictions/predictions-{today.month}-{today.day}.csv\", )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
